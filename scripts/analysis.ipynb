{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text_processor import preprocess_text\n",
    "from utils.utils import *\n",
    "from pathlib import Path\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_df = pd.read_csv(str(Path.cwd().parent)+ '/data/China_df.csv')\n",
    "hk_df = pd.read_csv(str(Path.cwd().parent) + '/data/HongKong_df.csv')\n",
    "taiwan_df = pd.read_csv(str(Path.cwd().parent) + '/data/taiwan_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\limyi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\limyi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Check if posts is indeed a DataFrame\n",
    "def process_column(posts, include_selftext = False):\n",
    "    if not isinstance(posts, pd.DataFrame):\n",
    "      raise ValueError(\"Input `posts` should be a pandas DataFrame.\")\n",
    "    texts = posts['title'].apply(preprocess_text)\n",
    "    if include_selftext:\n",
    "      # Add 'selftext' to each text if requested\n",
    "      texts += ' ' + posts['selftext'].apply(preprocess_text)\n",
    "\n",
    "    # Convert texts to a list format for further analysis\n",
    "    texts = texts.tolist()\n",
    "    return texts\n",
    "\n",
    "def top_n_terms(tfidf_matrix, feature_names, top_n=10):\n",
    "    mean_tfidf = tfidf_matrix.mean(axis=0).tolist()[0]\n",
    "\n",
    "    tfidf_scores = list(zip(feature_names, mean_tfidf))\n",
    "\n",
    "    tfidf_scores = sorted(tfidf_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return tfidf_scores[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('get', 0.01333039119919301),\n",
       " ('help', 0.012256770012414573),\n",
       " ('travel', 0.011604797339666018),\n",
       " ('shanghai', 0.011460644455774563),\n",
       " ('day', 0.011336978649633268),\n",
       " ('beijing', 0.011160581274037469),\n",
       " ('use', 0.0105954248048162),\n",
       " ('make', 0.009351604322744053),\n",
       " ('like', 0.009161583847548565),\n",
       " ('people', 0.008849990498166002)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "china_text = process_column(china_df)\n",
    "ch_tfidf_matrix, chi_feature_names = generate_tfidf_matrix(china_text)\n",
    "china_terms = top_n_terms(ch_tfidf_matrix, chi_feature_names)\n",
    "china_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('taipei', 0.04888235139069697),\n",
       " ('typhoon', 0.02169607534759792),\n",
       " ('day', 0.01917809839020844),\n",
       " ('travel', 0.015629144313575837),\n",
       " ('question', 0.015273628786330425),\n",
       " ('look', 0.01448716191344036),\n",
       " ('kaohsiung', 0.014308193133987903),\n",
       " ('best', 0.012743342652405714),\n",
       " ('buy', 0.012541095277490068),\n",
       " ('get', 0.011752293342682145)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taiwan_text = process_column(taiwan_df)\n",
    "tw_tfidf_matrix, tw_feature_names = generate_tfidf_matrix(taiwan_text)\n",
    "tw_terms = top_n_terms(tw_tfidf_matrix, tw_feature_names)\n",
    "tw_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('buy', 0.015322746482871583),\n",
       " ('get', 0.013398167656073571),\n",
       " ('look', 0.013257383115877795),\n",
       " ('anyone', 0.01278438485449765),\n",
       " ('recommendation', 0.011940126666620227),\n",
       " ('question', 0.011699494604170638),\n",
       " ('best', 0.011450014123299912),\n",
       " ('store', 0.011275080533516378),\n",
       " ('travel', 0.01048618992652609),\n",
       " ('help', 0.010281285146268162)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hk_text = process_column(hk_df)\n",
    "hk_tfidf_matrix, hk_feature_names = generate_tfidf_matrix(hk_text)\n",
    "hk_terms = top_n_terms(hk_tfidf_matrix, hk_feature_names)\n",
    "hk_terms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
